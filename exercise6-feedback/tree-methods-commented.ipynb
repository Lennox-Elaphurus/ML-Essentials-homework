{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997c6b5a",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e11123",
   "metadata": {},
   "source": [
    "Authors: \\\n",
    "Tuoxing Liu \\\n",
    "Sima Esmaeili \\\n",
    "Shruti Ghargi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc97042",
   "metadata": {},
   "source": [
    "# 1 Classification and Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b0df1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffcf16",
   "metadata": {},
   "source": [
    "## Base Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea27189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "      this class will later get the following attributes\n",
    "      all nodes:\n",
    "          features\n",
    "          responses\n",
    "      split nodes additionally:\n",
    "          left\n",
    "          right\n",
    "          split_index\n",
    "          threshold\n",
    "      leaf nodes additionally\n",
    "          prediction\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    '''\n",
    "      base class for RegressionTree and ClassificationTree\n",
    "    '''\n",
    "    def __init__(self, n_min=10):\n",
    "        '''n_min: minimum required number of instances in leaf nodes\n",
    "        '''\n",
    "        self.n_min = n_min \n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' return the prediction for the given 1-D feature vector x\n",
    "        '''\n",
    "        # first find the leaf containing the 1-D feature vector x\n",
    "        node = self.root\n",
    "        while not hasattr(node, \"prediction\"):\n",
    "            j = node.split_index\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        # finally, return the leaf's prediction\n",
    "        return node.prediction\n",
    "        \n",
    "    def train(self, features, responses, D_try=None):\n",
    "        '''\n",
    "        features: the feature matrix of the training set\n",
    "        response: the vector of responses\n",
    "        '''\n",
    "        N, D = features.shape\n",
    "        assert(responses.shape[0] == N)\n",
    "\n",
    "        if D_try is None:\n",
    "            D_try = int(np.sqrt(D))  # number of features to consider for each split decision\n",
    "        \n",
    "        # initialize the root node\n",
    "        self.root = Node()\n",
    "        self.root.features = features\n",
    "        self.root.responses = responses\n",
    "\n",
    "        # build the tree\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            active_indices = self.select_active_indices(D, D_try)\n",
    "            left, right = self.make_split_node(node, active_indices)\n",
    "            if left is None:  # no split found\n",
    "                self.make_leaf_node(node)\n",
    "            else:\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "    \n",
    "    def make_split_node(self, node, indices):\n",
    "        '''\n",
    "        node: the node to be split\n",
    "        indices: a numpy array of length 'D_try', containing the feature \n",
    "                         indices to be considered for the present split\n",
    "                         \n",
    "        return: None, None -- if no suitable split has been found, or\n",
    "                left, right -- the children of the split\n",
    "        '''\n",
    "        # all responses equal => no improvement possible by any split\n",
    "        if np.unique(node.responses).shape[0] == 1:\n",
    "            return None, None\n",
    "        \n",
    "        # find best feature j_min (among 'indices') and best threshold t_min for the split\n",
    "        l_min = float('inf')  # upper bound for the loss, later the loss of the best split\n",
    "        j_min, t_min = None, None\n",
    "\n",
    "        for j in indices:\n",
    "            thresholds = self.find_thresholds(node, j)\n",
    "\n",
    "            # compute loss for each threshold\n",
    "            for t in thresholds:\n",
    "                loss = self.compute_loss_for_split(node, j, t)\n",
    "\n",
    "                # remember the best split so far \n",
    "                # (the condition is never True when loss = float('inf') )\n",
    "                if loss < l_min:\n",
    "                    l_min = loss\n",
    "                    j_min = j\n",
    "                    t_min = t\n",
    "\n",
    "        if j_min is None:  # no split found\n",
    "            return None, None\n",
    "\n",
    "        # create children for the best split\n",
    "        left, right = self.make_children(node, j_min, t_min)\n",
    "\n",
    "        # turn the current 'node' into a split node\n",
    "        node.split_index = j_min\n",
    "        node.threshold = t_min\n",
    "        node.left = left\n",
    "        node.right = right\n",
    "        \n",
    "        # return the children (to be placed on the stack)\n",
    "        return left, right\n",
    "    \n",
    "    def select_active_indices(self, D, D_try):\n",
    "        ''' return a 1-D array with D_try randomly selected indices from 0...(D-1).\n",
    "        '''\n",
    "        return np.random.choice(D, D_try, replace=False)\n",
    "    \n",
    "    def find_thresholds(self, node, j):\n",
    "        ''' return: a 1-D array with all possible thresholds along feature j\n",
    "        '''\n",
    "        return np.sort(np.unique(node.features[:, j]))\n",
    "    \n",
    "    def make_children(self, node, j, t):\n",
    "        ''' execute the split in feature j at threshold t\n",
    "        \n",
    "            return: left, right -- the children of the split, with features and responses\n",
    "                                   properly assigned according to the split\n",
    "        '''\n",
    "        left = Node()\n",
    "        right = Node()\n",
    "\n",
    "        indices_left = node.features[:, j] <= t\n",
    "        indices_right = ~indices_left\n",
    "        \n",
    "        left.features = node.features[indices_left]\n",
    "        left.responses = node.responses[indices_left]\n",
    "        \n",
    "        right.features = node.features[indices_right]\n",
    "        right.responses = node.responses[indices_right]\n",
    "        \n",
    "        return left, right\n",
    "        \n",
    "    @abstractmethod\n",
    "    def make_leaf_node(self, node):\n",
    "        ''' Turn node into a leaf by computing and setting `node.prediction`\n",
    "        \n",
    "            (must be implemented in a subclass)\n",
    "        '''\n",
    "        raise NotImplementedError(\"make_leaf_node() must be implemented in a subclass.\")\n",
    "        \n",
    "    @abstractmethod\n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        ''' Return the resulting loss when the data are split along feature j at threshold t.\n",
    "            If the split is not admissible, return float('inf').\n",
    "        \n",
    "            (must be implemented in a subclass)\n",
    "        '''\n",
    "        raise NotImplementedError(\"compute_loss_for_split() must be implemented in a subclass.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe32bf1-60c9-4e8e-a86b-74a83f5f7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    '''\n",
    "      this class will later get the following attributes\n",
    "      all nodes:\n",
    "          features\n",
    "          responses\n",
    "      split nodes additionally:\n",
    "          left\n",
    "          right\n",
    "          split_index\n",
    "          threshold\n",
    "      leaf nodes additionally\n",
    "          prediction\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    '''\n",
    "      base class for RegressionTree and ClassificationTree\n",
    "    '''\n",
    "    def __init__(self, n_min=10):\n",
    "        '''n_min: minimum required number of instances in leaf nodes\n",
    "        '''\n",
    "        self.n_min = n_min \n",
    "    \n",
    "    def predict(self, x):\n",
    "        ''' return the prediction for the given 1-D feature vector x\n",
    "        '''\n",
    "        # first find the leaf containing the 1-D feature vector x\n",
    "        node = self.root\n",
    "        while not hasattr(node, \"prediction\"):\n",
    "            j = node.split_index\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        # finally, return the leaf's prediction\n",
    "        return node.prediction\n",
    "        \n",
    "    def train(self, features, responses, D_try=None):\n",
    "        '''\n",
    "        features: the feature matrix of the training set\n",
    "        response: the vector of responses\n",
    "        '''\n",
    "        N, D = features.shape\n",
    "        assert(responses.shape[0] == N)\n",
    "\n",
    "        if D_try is None:\n",
    "            D_try = int(np.sqrt(D))  # number of features to consider for each split decision\n",
    "        \n",
    "        # initialize the root node\n",
    "        self.root = Node()\n",
    "        self.root.features = features\n",
    "        self.root.responses = responses\n",
    "\n",
    "        # build the tree\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            active_indices = self.select_active_indices(D, D_try)\n",
    "            left, right = self.make_split_node(node, active_indices)\n",
    "            if left is None:  # no split found\n",
    "                self.make_leaf_node(node)\n",
    "            else:\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "    \n",
    "    def make_split_node(self, node, indices):\n",
    "        '''\n",
    "        node: the node to be split\n",
    "        indices: a numpy array of length 'D_try', containing the feature \n",
    "                         indices to be considered for the present split\n",
    "                         \n",
    "        return: None, None -- if no suitable split has been found, or\n",
    "                left, right -- the children of the split\n",
    "        '''\n",
    "        # all responses equal => no improvement possible by any split\n",
    "        if np.unique(node.responses).shape[0] == 1:\n",
    "            return None, None\n",
    "        \n",
    "        # find best feature j_min (among 'indices') and best threshold t_min for the split\n",
    "        l_min = float('inf')  # upper bound for the loss, later the loss of the best split\n",
    "        j_min, t_min = None, None\n",
    "\n",
    "        for j in indices:\n",
    "            thresholds = self.find_thresholds(node, j)\n",
    "\n",
    "            # compute loss for each threshold\n",
    "            for t in thresholds:\n",
    "                loss = self.compute_loss_for_split(node, j, t)\n",
    "\n",
    "                # remember the best split so far \n",
    "                # (the condition is never True when loss = float('inf') )\n",
    "                if loss < l_min:\n",
    "                    l_min = loss\n",
    "                    j_min = j\n",
    "                    t_min = t\n",
    "\n",
    "        if j_min is None:  # no split found\n",
    "            return None, None\n",
    "\n",
    "        # create children for the best split\n",
    "        left, right = self.make_children(node, j_min, t_min)\n",
    "\n",
    "        # turn the current 'node' into a split node\n",
    "        node.split_index = j_min\n",
    "        node.threshold = t_min\n",
    "        node.left = left\n",
    "        node.right = right\n",
    "        \n",
    "        # return the children (to be placed on the stack)\n",
    "        return left, right\n",
    "    \n",
    "    def select_active_indices(self, D, D_try):\n",
    "        ''' return a 1-D array with D_try randomly selected indices from 0...(D-1).\n",
    "        '''\n",
    "        return np.random.choice(D, D_try, replace=False)\n",
    "    \n",
    "    def find_thresholds(self, node, j):\n",
    "        ''' return: a 1-D array with all possible thresholds along feature j\n",
    "        '''\n",
    "        return np.sort(np.unique(node.features[:, j]))\n",
    "    \n",
    "    def make_children(self, node, j, t):\n",
    "        ''' execute the split in feature j at threshold t\n",
    "        \n",
    "            return: left, right -- the children of the split, with features and responses\n",
    "                                   properly assigned according to the split\n",
    "        '''\n",
    "        left = Node()\n",
    "        right = Node()\n",
    "\n",
    "        indices_left = node.features[:, j] <= t\n",
    "        indices_right = ~indices_left\n",
    "        \n",
    "        left.features = node.features[indices_left]\n",
    "        left.responses = node.responses[indices_left]\n",
    "        \n",
    "        right.features = node.features[indices_right]\n",
    "        right.responses = node.responses[indices_right]\n",
    "        \n",
    "        return left, right\n",
    "        \n",
    "    @abstractmethod\n",
    "    def make_leaf_node(self, node):\n",
    "        ''' Turn node into a leaf by computing and setting `node.prediction`\n",
    "        \n",
    "            (must be implemented in a subclass)\n",
    "        '''\n",
    "        raise NotImplementedError(\"make_leaf_node() must be implemented in a subclass.\")\n",
    "        \n",
    "    @abstractmethod\n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        ''' Return the resulting loss when the data are split along feature j at threshold t.\n",
    "            If the split is not admissible, return float('inf').\n",
    "        \n",
    "            (must be implemented in a subclass)\n",
    "        '''\n",
    "        raise NotImplementedError(\"compute_loss_for_split() must be implemented in a subclass.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09e1fdc5",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">In function find_thresholds, We didn't rule out the possible thresholds that will lead to less that n_min data points, but we do the same thing later.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70593f04",
   "metadata": {},
   "source": [
    "## Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bd406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree(Tree):\n",
    "    def __init__(self, n_min=10):\n",
    "        super(RegressionTree, self).__init__(n_min)\n",
    "        \n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        # return the loss if we would split the instance along feature j at threshold t\n",
    "        # or float('inf') if there is no feasible split\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        if np.sum(left_indices) < self.n_min or np.sum(right_indices) < self.n_min:\n",
    "            return float('inf')\n",
    "\n",
    "        left_responses = node.responses[left_indices]\n",
    "        right_responses = node.responses[right_indices]\n",
    "\n",
    "        left_loss = np.mean((left_responses - np.mean(left_responses))**2)\n",
    "        right_loss = np.mean((right_responses - np.mean(right_responses))**2)\n",
    "\n",
    "        return left_loss + right_loss\n",
    "    \n",
    "    def make_leaf_node(self, node):\n",
    "        # turn node into a leaf node by computing `node.prediction`\n",
    "        # (note: the prediction of a regression tree is a real number)\n",
    "        node.prediction = np.mean(node.responses)\n",
    "        \n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        # return the loss if we would split the instance along feature j at threshold t\n",
    "        # or float('inf') if there is no feasible split\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        if np.sum(left_indices) < self.n_min or np.sum(right_indices) < self.n_min:\n",
    "            return float('inf')\n",
    "\n",
    "        left_responses = node.responses[left_indices]\n",
    "        right_responses = node.responses[right_indices]\n",
    "\n",
    "        left_loss = np.mean((left_responses - np.mean(left_responses))**2)\n",
    "        right_loss = np.mean((right_responses - np.mean(right_responses))**2)\n",
    "\n",
    "        return left_loss + right_loss\n",
    "    \n",
    "    def make_leaf_node(self, node):\n",
    "        # turn node into a leaf node by computing `node.prediction`\n",
    "        # (note: the prediction of a regression tree is a real number)\n",
    "        node.prediction = np.mean(node.responses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f4113a1",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "We rule out the nodes that contain less than n_min points here.</br>\n",
    "We made a mistake when merging the files. We defined the same functions twice, but they are correct.</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83ec3a",
   "metadata": {},
   "source": [
    "## Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e95928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree(Tree):\n",
    "    '''implement classification tree so that it can handle arbitrary many classes\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, classes, n_min=10):\n",
    "        ''' classes: a 1-D array with the permitted class labels\n",
    "            n_min: minimum required number of instances in leaf nodes\n",
    "        '''\n",
    "        super(ClassificationTree, self).__init__(n_min)\n",
    "        self.classes = classes\n",
    "        \n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        # return the loss if we would split the instance along feature j at threshold t\n",
    "        # or float('inf') if there is no feasible split\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        if np.sum(left_indices) < self.n_min or np.sum(right_indices) < self.n_min:\n",
    "            return float('inf')\n",
    "\n",
    "        left_responses = node.responses[left_indices]\n",
    "        right_responses = node.responses[right_indices]\n",
    "\n",
    "        left_loss = self.compute_loss(left_responses)\n",
    "        right_loss = self.compute_loss(right_responses)\n",
    "\n",
    "        return (np.sum(left_indices) * left_loss + np.sum(right_indices) * right_loss) / np.sum(left_indices + right_indices)\n",
    "    \n",
    "    def compute_loss(self, responses):\n",
    "        class_counts = np.bincount(responses, minlength=len(self.classes))\n",
    "        class_probabilities = class_counts / np.sum(class_counts)\n",
    "\n",
    "        return self.compute_entropy(class_probabilities)\n",
    "    \n",
    "    def compute_entropy(self, probabilities):\n",
    "        probabilities = probabilities[probabilities > 0]\n",
    "        return -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    def make_leaf_node(self, node):\n",
    "        # turn node into a leaf node by computing `node.prediction`\n",
    "        # (note: the prediction of a classification tree is a class label)\n",
    "        class_counts = np.bincount(node.responses, minlength=len(self.classes))\n",
    "        node.prediction = np.argmax(class_counts)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "824d7a0e",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "We can use self.classes[np.argmax(p)] instead of np.argmax(class_counts) incase the class labels are not indexes.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5d858",
   "metadata": {},
   "source": [
    "## Evaluation of Regression and Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11b7e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "# read and prepare the digits data and extract 3s and 9s\n",
    "digits = load_digits()\n",
    "print(digits.data.shape, digits.target.shape)\n",
    "\n",
    "instances = (digits.target == 3) | (digits.target == 9)\n",
    "features = digits.data[instances, :]\n",
    "labels = digits.target[instances]\n",
    "\n",
    "# for regression, we use labels +1 and -1\n",
    "responses = np.array([1 if l == 3 else -1 for l in labels])\n",
    "\n",
    "assert(features.shape[0] == labels.shape[0] == responses.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db0abefb",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "Correct.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945762d",
   "metadata": {},
   "source": [
    "For Regression Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "283cf6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Tree Mean Accuracy: 0.38923872309061275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create an instance of RegressionTree\n",
    "regression_tree = RegressionTree()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "mse_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(features):\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_responses, test_responses = responses[train_index], responses[test_index]\n",
    "\n",
    "    # Train the regression tree\n",
    "    regression_tree.train(train_features, train_responses)\n",
    "\n",
    "    # Predict the responses for the test set\n",
    "    predictions = [regression_tree.predict(x) for x in test_features]\n",
    "\n",
    "    # Calculate the mean squared error (MSE)\n",
    "    mse = np.mean((test_responses - predictions) ** 2)\n",
    "    mse_scores.append(mse)\n",
    "\n",
    "# Calculate and print the mean MSE score\n",
    "mean_mse = np.mean(mse_scores)\n",
    "print(\"Regression Tree Mean Accuracy:\", mean_mse)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f39eed4",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "This accuracy seems to be much lower than the one in sample solution. But it's because we are using MSE score instead of accuracy here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6213ed",
   "metadata": {},
   "source": [
    "For Classification Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4931d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Tree Mean Accuracy: 0.8762176560121766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create an instance of ClassificationTree\n",
    "classification_tree = ClassificationTree(classes=np.unique(labels))\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(features, labels):\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "    # Train the classification tree\n",
    "    classification_tree.train(train_features, train_labels)\n",
    "\n",
    "    # Predict the labels for the test set\n",
    "    predictions = [classification_tree.predict(x) for x in test_features]\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy = np.mean(predictions == test_labels)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Calculate and print the mean accuracy score\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print(\"Classification Tree Mean Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e04f14ce",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "This accuracy seems to be right.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4097cc63-2be8-427f-8071-e59e5ca72faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7111962240792324\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from abc import abstractmethod\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class Node:\n",
    "    '''\n",
    "    This class will later get the following attributes:\n",
    "    - All nodes: features, responses\n",
    "    - Split nodes additionally: left, right, split_index, threshold\n",
    "    - Leaf nodes additionally: prediction\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "class Tree:\n",
    "    '''\n",
    "    Base class for RegressionTree and ClassificationTree\n",
    "    '''\n",
    "    def __init__(self, n_min=10):\n",
    "        '''\n",
    "        n_min: minimum required number of instances in leaf nodes\n",
    "        '''\n",
    "        self.n_min = n_min \n",
    "    \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Return the prediction for the given 1-D feature vector x\n",
    "        '''\n",
    "        node = self.root\n",
    "        while not hasattr(node, \"prediction\"):\n",
    "            j = node.split_index\n",
    "            if x[j] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.prediction\n",
    "        \n",
    "    def train(self, features, responses, D_try=None):\n",
    "        '''\n",
    "        features: the feature matrix of the training set\n",
    "        response: the vector of responses\n",
    "        '''\n",
    "        N, D = features.shape\n",
    "        assert(responses.shape[0] == N)\n",
    "\n",
    "        if D_try is None:\n",
    "            D_try = int(np.sqrt(D))  # number of features to consider for each split decision\n",
    "        \n",
    "        self.root = Node()\n",
    "        self.root.features = features\n",
    "        self.root.responses = responses\n",
    "\n",
    "        stack = [self.root]\n",
    "        while len(stack):\n",
    "            node = stack.pop()\n",
    "            active_indices = self.select_active_indices(D, D_try)\n",
    "            left, right = self.make_split_node(node, active_indices)\n",
    "            if left is None:  # no split found\n",
    "                self.make_leaf_node(node)\n",
    "            else:\n",
    "                stack.append(left)\n",
    "                stack.append(right)\n",
    "    \n",
    "    def make_split_node(self, node, indices):\n",
    "        '''\n",
    "        node: the node to be split\n",
    "        indices: a numpy array of length 'D_try', containing the feature \n",
    "                 indices to be considered for the present split\n",
    "        return: None, None -- if no suitable split has been found, or\n",
    "                left, right -- the children of the split\n",
    "        '''\n",
    "        if np.unique(node.responses).shape[0] == 1:\n",
    "            return None, None\n",
    "        \n",
    "        l_min = float('inf')  # upper bound for the loss, later the loss of the best split\n",
    "        j_min, t_min = None, None\n",
    "\n",
    "        for j in indices:\n",
    "            thresholds = self.find_thresholds(node, j)\n",
    "            for t in thresholds:\n",
    "                loss = self.compute_loss_for_split(node, j, t)\n",
    "                if loss < l_min:\n",
    "                    l_min = loss\n",
    "                    j_min = j\n",
    "                    t_min = t\n",
    "\n",
    "        if j_min is None:  # no split found\n",
    "            return None, None\n",
    "\n",
    "        left, right = self.make_children(node, j_min, t_min)\n",
    "\n",
    "        node.split_index = j_min\n",
    "        node.threshold = t_min\n",
    "        node.left = left\n",
    "        node.right = right\n",
    "        \n",
    "        return left, right\n",
    "    \n",
    "    def select_active_indices(self, D, D_try):\n",
    "        '''\n",
    "        Return a 1-D array with D_try randomly selected indices from 0...(D-1).\n",
    "        '''\n",
    "        return np.random.choice(D, D_try, replace=False)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def find_thresholds(self, node, j):\n",
    "        '''\n",
    "        Return a 1-D array with all possible thresholds along the j-th feature.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        '''\n",
    "        Return the loss of the split at feature j and threshold t.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def make_leaf_node(self, node):\n",
    "        '''\n",
    "        Create a leaf node from the given node, setting the prediction value.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def make_children(self, node, j, t):\n",
    "        '''\n",
    "        Create left and right children nodes from the given node, splitting it based on feature j and threshold t.\n",
    "        Return left, right\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "\n",
    "class ClassificationTree(Tree):\n",
    "    '''\n",
    "    Decision tree for classification problems\n",
    "    '''\n",
    "    def __init__(self, n_min=10):\n",
    "        super().__init__(n_min)\n",
    "        \n",
    "    def find_thresholds(self, node, j):\n",
    "        features = node.features[:, j]\n",
    "        thresholds = np.unique(features)\n",
    "        return (thresholds[1:] + thresholds[:-1]) / 2\n",
    "    \n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = node.features[:, j] > t\n",
    "        left_counts = np.bincount(node.responses[left_indices], minlength=10)\n",
    "        right_counts = np.bincount(node.responses[right_indices], minlength=10)\n",
    "        left_probs = left_counts / np.sum(left_counts)\n",
    "        right_probs = right_counts / np.sum(right_counts)\n",
    "        left_loss = -np.sum(left_probs * np.log(left_probs + 1e-10))\n",
    "        right_loss = -np.sum(right_probs * np.log(right_probs + 1e-10))\n",
    "        return left_loss + right_loss\n",
    "    \n",
    "    def make_leaf_node(self, node):\n",
    "        counts = np.bincount(node.responses, minlength=10)\n",
    "        node.prediction = np.argmax(counts)\n",
    "    \n",
    "    def make_children(self, node, j, t):\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = node.features[:, j] > t\n",
    "\n",
    "        left = Node()\n",
    "        left.features = node.features[left_indices]\n",
    "        left.responses = node.responses[left_indices]\n",
    "\n",
    "        right = Node()\n",
    "        right.features = node.features[right_indices]\n",
    "        right.responses = node.responses[right_indices]\n",
    "\n",
    "        return left, right\n",
    "\n",
    "\n",
    "class RegressionTree(Tree):\n",
    "    '''\n",
    "    Decision tree for regression problems\n",
    "    '''\n",
    "    def __init__(self, n_min=10):\n",
    "        super().__init__(n_min)\n",
    "    \n",
    "    def find_thresholds(self, node, j):\n",
    "        return np.unique(node.features[:, j])\n",
    "    \n",
    "    def compute_loss_for_split(self, node, j, t):\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = node.features[:, j] > t\n",
    "        left_targets = node.responses[left_indices]\n",
    "        right_targets = node.responses[right_indices]\n",
    "        left_loss = np.mean(np.square(left_targets - np.mean(left_targets)))\n",
    "        right_loss = np.mean(np.square(right_targets - np.mean(right_targets)))\n",
    "        return left_loss + right_loss\n",
    "    \n",
    "    def make_leaf_node(self, node):\n",
    "        node.prediction = np.mean(node.responses)\n",
    "    \n",
    "    def make_children(self, node, j, t):\n",
    "        left_indices = node.features[:, j] <= t\n",
    "        right_indices = node.features[:, j] > t\n",
    "\n",
    "        left = Node()\n",
    "        left.features = node.features[left_indices]\n",
    "        left.responses = node.responses[left_indices]\n",
    "\n",
    "        right = Node()\n",
    "        right.features = node.features[right_indices]\n",
    "        right.responses = node.responses[right_indices]\n",
    "\n",
    "        return left, right\n",
    "\n",
    "\n",
    "# Example usage\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf = ClassificationTree()\n",
    "    clf.train(X_train, y_train)\n",
    "\n",
    "    predictions = [clf.predict(x) for x in X_test]\n",
    "    accuracy.append(np.mean(predictions == y_test))\n",
    "\n",
    "mean_accuracy = np.mean(accuracy)\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b797d6-8fcd-455f-9b2e-ba554ba2a277",
   "metadata": {},
   "source": [
    "ex. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79b75c58-c2df-47c2-b9ad-3d4acd8cdaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7859146308025549\n",
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.value = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Find the best feature and threshold to split the data\n",
    "        best_score = float(\"inf\")\n",
    "        for feature_idx in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature_idx] <= threshold\n",
    "                right_indices = X[:, feature_idx] > threshold\n",
    "                score = self.calculate_score(y, y[left_indices], y[right_indices])\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    self.feature_idx = feature_idx\n",
    "                    self.threshold = threshold\n",
    "\n",
    "        # Split the data based on the best feature and threshold\n",
    "        left_indices = X[:, self.feature_idx] <= self.threshold\n",
    "        right_indices = X[:, self.feature_idx] > self.threshold\n",
    "\n",
    "        if np.all(left_indices) or np.all(right_indices):\n",
    "            self.value = np.mean(y)\n",
    "        else:\n",
    "            self.left = DecisionTree()\n",
    "            self.left.fit(X[left_indices], y[left_indices])\n",
    "            self.right = DecisionTree()\n",
    "            self.right.fit(X[right_indices], y[right_indices])\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.value is not None:\n",
    "            return np.full(X.shape[0], self.value)\n",
    "        else:\n",
    "            left_indices = X[:, self.feature_idx] <= self.threshold\n",
    "            right_indices = X[:, self.feature_idx] > self.threshold\n",
    "            y_pred = np.zeros(X.shape[0])\n",
    "            y_pred[left_indices] = self.left.predict(X[left_indices])\n",
    "            y_pred[right_indices] = self.right.predict(X[right_indices])\n",
    "            return y_pred\n",
    "\n",
    "    def calculate_score(self, y, left_y, right_y):\n",
    "        left_score = np.sum((left_y - np.mean(y)) ** 2)\n",
    "        right_score = np.sum((right_y - np.mean(y)) ** 2)\n",
    "        return left_score + right_score\n",
    "\n",
    "\n",
    "class RegressionForest:\n",
    "    def __init__(self, num_trees=10):\n",
    "        self.num_trees = num_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.num_trees):\n",
    "            tree = DecisionTree()\n",
    "            bootstrap_indices = resample(range(X.shape[0]), replace=True)\n",
    "            tree.fit(X[bootstrap_indices], y[bootstrap_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += tree.predict(X)\n",
    "        return predictions / self.num_trees\n",
    "\n",
    "\n",
    "class ClassificationForest:\n",
    "    def __init__(self, num_trees=10):\n",
    "        self.num_trees = num_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.num_trees):\n",
    "            tree = DecisionTree()\n",
    "            bootstrap_indices = resample(range(X.shape[0]), replace=True)\n",
    "            tree.fit(X[bootstrap_indices], y[bootstrap_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for tree in self.trees:\n",
    "            predictions += tree.predict(X)\n",
    "        return np.round(predictions / self.num_trees)\n",
    "\n",
    "\n",
    "# Example usage for regression\n",
    "X, y = np.random.randn(100, 5), np.random.randn(100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "forest = RegressionForest(num_trees=10)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Example usage for classification\n",
    "X, y = np.random.randn(100, 5), np.random.randint(0, 2, size=100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "forest = ClassificationForest(num_trees=10)\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25c3193",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "We should not submit duplicate codes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f07be-c7c8-4cae-864e-3df205628f7f",
   "metadata": {},
   "source": [
    "ex. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c2a5662-6636-4cba-94f5-a04e022b8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Confusion Matrix:\n",
      "[[13  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 11  0  0  0  0  0  0  0  0]\n",
      " [ 0  2 11  0  1  0  0  0  0  0]\n",
      " [ 0  0  1  6  0  0  0  0  0  1]\n",
      " [ 0  1  0  0 12  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  4  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  9  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  1]\n",
      " [ 0  0  0  0  0  0  0  2  4  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Select a smaller subset of the dataset\n",
    "X_subset = X[:500]\n",
    "y_subset = y[:500]\n",
    "\n",
    "# Split the subset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.2, random_state=42)\n",
    "\n",
    "class ClassificationTree:\n",
    "    def __init__(self):\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.label = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            self.label = y[0]\n",
    "            return\n",
    "\n",
    "        num_features = X.shape[1]\n",
    "        best_score = float('inf')\n",
    "\n",
    "        for feature_idx in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X[:, feature_idx] <= threshold\n",
    "                right_indices = X[:, feature_idx] > threshold\n",
    "\n",
    "                score = self.calculate_score(y, left_indices, right_indices)\n",
    "\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    self.feature_idx = feature_idx\n",
    "                    self.threshold = threshold\n",
    "\n",
    "        left_indices = X[:, self.feature_idx] <= self.threshold\n",
    "        right_indices = X[:, self.feature_idx] > self.threshold\n",
    "\n",
    "        self.left = ClassificationTree()\n",
    "        self.left.fit(X[left_indices], y[left_indices])\n",
    "\n",
    "        self.right = ClassificationTree()\n",
    "        self.right.fit(X[right_indices], y[right_indices])\n",
    "\n",
    "    def calculate_score(self, y, left_indices, right_indices):\n",
    "        if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "            return float('inf')\n",
    "\n",
    "        left_mean = np.mean(y[left_indices]) if len(y[left_indices]) > 0 else 0.0\n",
    "        right_mean = np.mean(y[right_indices]) if len(y[right_indices]) > 0 else 0.0\n",
    "\n",
    "        left_score = np.sum((y[left_indices] - left_mean) ** 2)\n",
    "        right_score = np.sum((y[right_indices] - right_mean) ** 2)\n",
    "\n",
    "        return left_score + right_score\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.label is not None:\n",
    "            return self.label\n",
    "\n",
    "        if X[self.feature_idx] <= self.threshold:\n",
    "            return self.left.predict(X)\n",
    "        else:\n",
    "            return self.right.predict(X)\n",
    "\n",
    "class ClassificationForest:\n",
    "    def __init__(self, num_trees):\n",
    "        self.num_trees = num_trees\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.num_trees):\n",
    "            tree = ClassificationTree()\n",
    "            bootstrap_indices = np.random.choice(range(X.shape[0]), size=X.shape[0], replace=True)\n",
    "            tree.fit(X[bootstrap_indices], y[bootstrap_indices])\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((X.shape[0], len(self.trees)))\n",
    "\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            for j in range(X.shape[0]):\n",
    "                predictions[j, i] = tree.predict(X[j])\n",
    "\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=predictions)\n",
    "\n",
    "# Create the forest with 10 trees\n",
    "forest = ClassificationForest(num_trees=10)\n",
    "\n",
    "# Fit the forest on the training set\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy and confusion matrix\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c63f7df6",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "Seems to be correct, but better to draw a figure.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09669acf-9392-4800-9e8a-cb71aa794404",
   "metadata": {},
   "source": [
    "ex. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2301291d-477f-4ee4-9a5f-3f1da36cf11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   3  23 152]\n",
      " [  0   0  15   0  13   4   1   0   1 148]\n",
      " [  0   0   5   1   5   7   6   6  37 110]\n",
      " [  0   0   0   0   0   2   0   0  15 166]\n",
      " [  0   0   0   1   0   0   0   0  10 170]\n",
      " [  1   1   0   0   0   1   0   1  17 161]\n",
      " [  0   0  11   1   1   0   1   0  15 152]\n",
      " [  1  14   5   2   2   0   0   0  10 145]\n",
      " [  0   0   0   0   0   0   0   0   3 171]\n",
      " [  1   3   2   0   0   0   1   2   4 167]]\n",
      "Accuracy: 0.10016867842773136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class RegressionTree:\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "        self.threshold = None\n",
    "        self.feature_idx = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.mean = None\n",
    "\n",
    "    def fit(self, X, y, depth=0):\n",
    "        if depth == self.max_depth or np.unique(y).size == 1:\n",
    "            self.mean = np.mean(y)\n",
    "            return\n",
    "\n",
    "        m, n = X.shape\n",
    "        best_mse = np.inf\n",
    "\n",
    "        for feature_idx in range(n):\n",
    "            feature_values = np.unique(X[:, feature_idx])\n",
    "            for threshold in feature_values:\n",
    "                left_indices = X[:, feature_idx] <= threshold\n",
    "                right_indices = X[:, feature_idx] > threshold\n",
    "\n",
    "                if len(y[left_indices]) == 0 or len(y[right_indices]) == 0:\n",
    "                    continue\n",
    "\n",
    "                left_mse = np.mean((y[left_indices] - np.mean(y[left_indices])) ** 2)\n",
    "                right_mse = np.mean((y[right_indices] - np.mean(y[right_indices])) ** 2)\n",
    "                mse = left_mse + right_mse\n",
    "\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    self.threshold = threshold\n",
    "                    self.feature_idx = feature_idx\n",
    "\n",
    "        if self.feature_idx is None:\n",
    "            self.mean = np.mean(y)\n",
    "            return\n",
    "\n",
    "        left_indices = X[:, self.feature_idx] <= self.threshold\n",
    "        right_indices = X[:, self.feature_idx] > self.threshold\n",
    "\n",
    "        self.left = RegressionTree(max_depth=self.max_depth)\n",
    "        self.left.fit(X[left_indices], y[left_indices], depth + 1)\n",
    "\n",
    "        self.right = RegressionTree(max_depth=self.max_depth)\n",
    "        self.right.fit(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.feature_idx is None:\n",
    "            return self.mean\n",
    "\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        left_indices = X[:, self.feature_idx] <= self.threshold\n",
    "        right_indices = X[:, self.feature_idx] > self.threshold\n",
    "\n",
    "        predictions[left_indices] = self.left.predict(X[left_indices])\n",
    "        predictions[right_indices] = self.right.predict(X[right_indices])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "class RegressionForest(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, num_trees=10, max_depth=3):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def bootstrap_sampling(self, X, y, class_label):\n",
    "        class_indices = np.where(y == class_label)[0]\n",
    "        rest_indices = np.where(y != class_label)[0]\n",
    "        bootstrap_indices = np.random.choice(class_indices, size=(len(class_indices),), replace=True)\n",
    "        bootstrap_indices = np.concatenate((bootstrap_indices, np.random.choice(rest_indices, size=(len(class_indices),), replace=True)))\n",
    "        return bootstrap_indices\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for class_label in np.unique(y):\n",
    "            for _ in range(self.num_trees):\n",
    "                bootstrap_indices = self.bootstrap_sampling(X, y, class_label)\n",
    "                tree = RegressionTree(max_depth=self.max_depth)\n",
    "                tree.fit(X[bootstrap_indices], y[bootstrap_indices])\n",
    "                self.trees.append((class_label, tree))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(X), len(np.unique(y)) + 1))\n",
    "\n",
    "        for class_label, tree in self.trees:\n",
    "            tree_predictions = tree.predict(X)\n",
    "            predictions[:, class_label] += tree_predictions\n",
    "\n",
    "        predictions[:, -1] = -np.sum(predictions[:, :-1], axis=1)\n",
    "\n",
    "        return np.argmax(predictions, axis=1)\n",
    "\n",
    "# Load the digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Create a RegressionForest with 10 trees and maximum depth of 3\n",
    "forest = RegressionForest(num_trees=10, max_depth=3)\n",
    "\n",
    "# Perform 5-fold cross-validation and obtain predicted labels\n",
    "y_pred = cross_val_predict(forest, X, y, cv=5)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(confusion, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xticks(np.arange(10))\n",
    "plt.yticks(np.arange(10))\n",
    "plt.show()\n",
    "\n",
    "print(confusion)\n",
    "# Calculate and print the accuracy score\n",
    "accuracy = cross_val_score(forest, X, y, cv=5).mean()\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ec4c0d1",
   "metadata": {},
   "source": [
    "<div style=\"color: green; font-weight:bold\">\n",
    "Wrong.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
